{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.path.extend([\"../src\", \"..\"])\n",
    "import sensai\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import *\n",
    "import config\n",
    "\n",
    "cfg = config.get_config()\n",
    "sensai.util.logging.configureLogging()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks\n",
    "\n",
    "Neural networks being a very powerful class of models, especially in cases where the learning of representations from low-level information (such as pixels, audio samples or text) is key, sensAI provides many useful abstractions for dealing with this class of models, facilitating data handling, learning and evaluation.\n",
    "\n",
    "sensAI mainly provides abstractions for PyTorch, but there is also rudimentary support for TensorFlow.\n",
    "\n",
    "## Image Classification\n",
    "\n",
    "As an example use case, let us solve the classification problem of classifying digits in pixel images from the MNIST dataset. Images are greyscale (no colour information) and 28x28 pixels in size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnistDF = pd.read_csv(cfg.datafile_path(\"mnist_train.csv.zip\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data frame contains one column for every pixel, each pixel being represented by an 8-bit integer (0 to 255)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnistDF.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create the I/O data for our experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnistIoData = sensai.InputOutputData.fromDataFrame(mnistDF, \"label\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the image data separated from the labels, let's write a function to restore the 2D image arrays and take a look at some of the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def reshape2DImage(series):\n",
    "    return series.values.reshape(28, 28)\n",
    "\n",
    "fig, axs = plt.subplots(nrows=1, ncols=5, figsize=(10, 5))\n",
    "for i in range(5):\n",
    "    axs[i].imshow(reshape2DImage(mnistIoData.inputs.iloc[i]), cmap=\"binary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying Predefined Models\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create an evaluator in order to test the performance of our models, randomly splitting the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluatorParams = sensai.evaluation.VectorClassificationModelEvaluatorParams(fractionalSplitTestFraction=0.2)\n",
    "evalUtil = sensai.evaluation.ClassificationEvaluationUtil(mnistIoData, evaluatorParams=evaluatorParams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One pre-defined model we could try is a simple multi-layer perceptron. A PyTorch-based implementation is provided via class `MultiLayerPerceptronVectorClassificationModel`. This implementation supports CUDA-accelerated computations (on Nvidia GPUs), yet we shall stick to CPU-based computation (cuda=False) in this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sensai.torch\n",
    "\n",
    "nnOptimiserParams = sensai.torch.NNOptimiserParams(earlyStoppingEpochs=10, batchSize=54)\n",
    "torchMLPModel = sensai.torch.models.MultiLayerPerceptronVectorClassificationModel(hiddenDims=(50, 20), cuda=False,\n",
    "        normalisationMode=sensai.torch.NormalisationMode.MAX_ALL, nnOptimiserParams=nnOptimiserParams, pDropout=0.0).withName(\"MLP\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural networks work best on **normalised inputs**, so we have opted to apply basic normalisation by specifying a normalisation mode which will transforms inputs by dividing by the maximum value found across all columns in the training data. For more elaborate normalisation options, we could have used a data frame transformer (DFT), particularly `DFTNormalisation` or `DFTSkLearnTransformer`.\n",
    "\n",
    "sensAI's default **neural network training algorithm** is based on early stopping, which involves checking, in regular intervals, the performance of the model on a validation set (which is split from the training set) and ultimately selecting the model that performed best on the validation set. You have full control over the loss evaluation method used to select the best model (by passing a respective `NNLossEvaluator` instance to NNOptimiserParams) as well as the method that is used to split the training set into the actual training set and the validation set (by adding a `DataFrameSplitter` to the model or using a custom `TorchDataSetProvider`).\n",
    "\n",
    "Given the vectorised nature of our MNIST dataset, we can apply any type of model which can accept the numeric inputs. Let's compare the neural network we defined above against another pre-defined model, which is based on a scikit-learn implementation and uses decision trees rather than neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomForestModel = sensai.sklearn.classification.SkLearnRandomForestVectorClassificationModel(min_samples_leaf=1, n_estimators=10) \\\n",
    "    .withName(\"RandomForest\")\n",
    "\n",
    "evalUtil.compareModels([randomForestModel, torchMLPModel])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both models perform reasonably well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Custom CNN Model\n",
    "\n",
    "Given that this is an image recognition problem, it can be sensible to apply convolutional neural networks (CNNs), which can analyse smaller patches of the image in order to generate more high-level features from them.\n",
    "\n",
    "To define a custom neural network model that uses PyTorch, we need to implement a new model class. For classification and regression, sensAI provides the base classes `TorchVectorClassificationModel` and `TorchVectorRegressionModel` respectively. Ultimately, these classes will wrap an instance of `torch.nn.Module`, the base class for neural networks in PyTorch.\n",
    "\n",
    "In the following, we shall define a model which uses multiple convolutions, a max-pooling layer and a multi-layer perceptron at the end in order to produce the classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class CnnModel(sensai.torch.TorchVectorClassificationModel):\n",
    "    def __init__(self, cuda: bool, kernelSize: int, numConv: int, poolingKernelSize: int, mlpHiddenDims: Sequence[int], \n",
    "            nnOptimiserParams: sensai.torch.NNOptimiserParams, pDropout=0.0):\n",
    "        self.cuda = cuda\n",
    "        self.outputActivationFn = sensai.torch.ActivationFunction.LOG_SOFTMAX\n",
    "        self.kernelSize = kernelSize\n",
    "        self.numConv = numConv\n",
    "        self.poolingKernelSize = poolingKernelSize\n",
    "        self.mlpHiddenDims = mlpHiddenDims\n",
    "        self.pDropout = pDropout\n",
    "        super().__init__(sensai.torch.ClassificationOutputMode.forActivationFn(self.outputActivationFn),\n",
    "            modelClass=self.VectorTorchModel, modelArgs=[self], nnOptimiserParams=nnOptimiserParams)\n",
    "        self.withInputTensoriser(self.InputTensoriser())\n",
    "\n",
    "    class InputTensoriser(sensai.torch.RuleBasedTensoriser):\n",
    "        def _tensorise(self, df: pd.DataFrame) -> Union[torch.Tensor, List[torch.Tensor]]:\n",
    "            images = [reshape2DImage(row) for _, row in df.iterrows()]\n",
    "            return torch.tensor(np.stack(images)).float() / 255\n",
    "\n",
    "    class VectorTorchModel(sensai.torch.VectorTorchModel):\n",
    "        def __init__(self, vecModel: \"CnnModel\"):\n",
    "            super().__init__(vecModel.cuda)\n",
    "            self._vecModel = vecModel\n",
    "\n",
    "        def createTorchModuleForDims(self, inputDim: int, outputDim: int) -> torch.nn.Module:\n",
    "            return self.Module(int(np.sqrt(inputDim)), outputDim, self._vecModel)\n",
    "\n",
    "        class Module(torch.nn.Module):\n",
    "            def __init__(self, imageDim, outputDim, vecModel: \"CnnModel\"):\n",
    "                super().__init__()\n",
    "                k = vecModel.kernelSize\n",
    "                p = vecModel.poolingKernelSize\n",
    "                self.cnn = torch.nn.Conv2d(1, vecModel.numConv, (k, k))\n",
    "                self.pool = torch.nn.MaxPool2d((p, p))\n",
    "                self.dropout = torch.nn.Dropout(p=vecModel.pDropout)\n",
    "                reducedDim = (imageDim-k+1)/p\n",
    "                if int(reducedDim) != reducedDim:\n",
    "                    raise ValueError(f\"Pooling kernel size {p} is not a divisor of post-convolution dimension {imageDim-k+1}\")\n",
    "                self.mlp = sensai.torch.models.MultiLayerPerceptron(vecModel.numConv * int(reducedDim)**2, outputDim, vecModel.mlpHiddenDims,\n",
    "                    outputActivationFn=vecModel.outputActivationFn.getTorchFunction(),\n",
    "                    hidActivationFn=sensai.torch.ActivationFunction.RELU.getTorchFunction(),\n",
    "                    pDropout=vecModel.pDropout)\n",
    "\n",
    "            def forward(self, x):\n",
    "                x = self.cnn(x.unsqueeze(1))\n",
    "                x = self.pool(x)\n",
    "                x = x.view(x.shape[0], -1)\n",
    "                x = self.dropout(x)\n",
    "                return self.mlp(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very little code is required in addition to the actual torch module.\n",
    "The outer class, which provides the sensAI `VectorModel` features, serves mainly to hold the parameters, and the inner class inheriting from `VectorTorchModel` serves as a factory for the `torch.nn.Module`, providing us with the input and output dimensions (number of input columns and number of classes respectively) based on the data. Because we take the dimensions directly from the input, this model could easily process other image sizes than 28x28 and we furthermore end up with fewer magic numbers in the code.\n",
    "\n",
    "The inner class `InputTensoriser`, which is instantiated and passed as the input tensoriser for the model, serves to convert the input data frame into a tensor. It could perform arbitrary computations in order to produce, from a data frame with N rows, one or more tensors of length N (first dimension equal to N) that will ultimately be fed to the neural network.\n",
    "\n",
    "Let's instantiate our model and see how it performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnOptimiserParams = sensai.torch.NNOptimiserParams(optimiser=sensai.torch.Optimiser.ADAMW, optimiserLR=0.01, batchSize=1024, \n",
    "    earlyStoppingEpochs=3)\n",
    "cnnModel = CnnModel(cuda=False, kernelSize=5, numConv=32, poolingKernelSize=2, mlpHiddenDims=(200,20),\n",
    "    nnOptimiserParams=nnOptimiserParams).withName(\"CNN\")\n",
    "\n",
    "evalData = evalUtil.performSimpleEvaluation(cnnModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model does slightly improve upon the MLP model we evaluated earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparisonData = evalUtil.compareModels([torchMLPModel, cnnModel, randomForestModel], fitModels=False)\n",
    "comparisonData.resultsDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Could the CNN model have produced even better results? Let's take a look at some examples where the CNN model went wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "misclassified = evalData.getMisclassifiedTriplesPredTrueInput()\n",
    "fig, axs = plt.subplots(nrows=3, ncols=3, figsize=(9,9))\n",
    "for i, (predClass, trueClass, input) in enumerate(misclassified[:9]):\n",
    "    axs[i//3][i%3].imshow(reshape2DImage(input), cmap=\"binary\")\n",
    "    axs[i//3][i%3].set_title(f\"{trueClass} misclassified as {predClass}\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While some of these examples are indeed ambiguous, there still is room for improvement."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9b3442ae4bdb9561e722e28424c33a03c16d40b3aa50369b79d367cad7b1adea"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('sensai')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
